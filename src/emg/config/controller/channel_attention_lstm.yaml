data_dir: data/controller

model:
  _target_: emg.model.channel_attention.ChannelAttentionLSTMController
  num_channels: 8
  emg_sample_rate: 500.0
  window_length_s: ${training.window_length_s}
  fft_window: 64
  fft_stride: 32
  d_model: 64
  num_heads: 4
  num_layers: 2
  dim_feedforward: 64
  pooling: mean
  projection_dim: 64
  lstm_hidden_dim: 64
  lstm_num_layers: 1
  dropout: 0.1

  spec_augment:
    _target_: emg.model.specaug.SpectrogramSpecMaskAug
    dims: TF
    max_num_masks: [2, 2]
    max_mask_lengths: [5, 20]
    mask_value: 0.0

preprocessing:
  highpass_freq: 20.0
  emg_scale: 1

training:
  seed: 42
  window_length_s: 2.0
  stride_s: 0.5
  batch_size: 512
  num_epochs: 500
  grad_clip_norm: 1.0
  eval_interval: 10
  eval_split: 0.1
  save_interval: 25
  device: mps
  use_class_weights: true
  action_loss_weight: 1.0
  dxdy_loss_weight: 1.0
  mask_zero_dxdy_groups: false
  jitter: true

optimizer:
  _target_: torch.optim.AdamW
  lr: 3e-4
  weight_decay: 0.01
